{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO1NMPplhPa7zYpz6sVA2SP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szh141/Examples/blob/main/One_Hot_encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "ibA6_iBV6ooz",
        "outputId": "cbddf527-f169-47c6-82f6-9c1e500e09aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbzElEQVR4nO3dcXSU9b3n8c8AyYCaDIaQTFICDaCiAuktQkxRipJDiHs9gKxH1O6CxwMLDW6RWt30Kmjbc9Jir7q6FM72VtB7BJRzBFZqcTGYcNWELhEul20bCSeVsJBQ2ZIJQUIgv/2DdexIIj7DTL4z4f065zmHzDy/PF8fB98+zPDE55xzAgCgl/WzHgAAcGUiQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMQA6wG+rKurS0ePHlVaWpp8Pp/1OAAAj5xzamtrU25urvr16/k6J+ECdPToUeXl5VmPAQC4TE1NTRo2bFiPzydcgNLS0iRJt+kuDVCK8TQAAK/OqVPv6+3wf897ErcArVq1Ss8++6yam5tVUFCgl156SZMmTbrkus//2G2AUjTAR4AAIOn8/zuMXuptlLh8COH111/XsmXLtGLFCn300UcqKChQSUmJjh8/Ho/DAQCSUFwC9Nxzz2nBggV66KGHdNNNN2nNmjW66qqr9PLLL8fjcACAJBTzAJ09e1Z1dXUqLi7+4iD9+qm4uFg1NTUX7d/R0aFQKBSxAQD6vpgH6NNPP9X58+eVnZ0d8Xh2draam5sv2r+iokKBQCC88Qk4ALgymP9F1PLycrW2toa3pqYm65EAAL0g5p+Cy8zMVP/+/dXS0hLxeEtLi4LB4EX7+/1++f3+WI8BAEhwMb8CSk1N1YQJE1RZWRl+rKurS5WVlSoqKor14QAASSoufw9o2bJlmjdvnm655RZNmjRJL7zwgtrb2/XQQw/F43AAgCQUlwDdd999+stf/qLly5erublZ3/rWt7R9+/aLPpgAALhy+ZxzznqIvxUKhRQIBDRVM7kTAgAkoXOuU1XaqtbWVqWnp/e4n/mn4AAAVyYCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwMcB6ACDZ+QZ4/2104j9MjMMkyWfIv7V5XuP2HIjDJLDAFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkaJXfbxmkuc1gzJPx2GS2Onfv8vzmn2TVsVhkuQz5rUyz2tG7onDIDDBFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkaJXVdyxyfOae685EYdJkAg+uP+Xntfc9fFjntcM+acaz2sQf1wBAQBMECAAgImYB+jpp5+Wz+eL2MaMGRPrwwAAklxc3gO6+eab9e67735xkAG81QQAiBSXMgwYMEDBYDAe3xoA0EfE5T2ggwcPKjc3VyNHjtSDDz6ow4cP97hvR0eHQqFQxAYA6PtiHqDCwkKtW7dO27dv1+rVq9XY2Kjbb79dbW1t3e5fUVGhQCAQ3vLy8mI9EgAgAcU8QKWlpbr33ns1fvx4lZSU6O2339bJkyf1xhtvdLt/eXm5Wltbw1tTU1OsRwIAJKC4fzpg8ODBuv7669XQ0NDt836/X36/P95jAAASTNz/HtCpU6d06NAh5eTkxPtQAIAkEvMAPfbYY6qurtaf//xnffjhh5o9e7b69++v+++/P9aHAgAksZj/EdyRI0d0//3368SJExo6dKhuu+021dbWaujQobE+FAAgicU8QBs3boz1twTQRw3pN8jzmn9+8h89r5nX+UPPayTp2le4iWk8cS84AIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE3H8gHfC3Xp1V7HnNKyn9Pa/pyLra8xpJapzj/VhjVoeiOlZvWP/bl6Nal95vYIwniZ1fNk/3vGbou59EdaxzUa3C18UVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwN2z0qvN/PNgrx0mJct3173pf0xXlsbw68XCR5zV+X2L/Fp/3yZ2e1/z1/jTPa879nybPaxB/XAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYS+06FQDLw+TwvOb7Y+41FX3n8Oc9r/L5Uz2t60+73b/S8ZuQnNXGYBBa4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAzUuAynXj4Vs9r9vzDf4viSIl9Y9HaDu9rMve62A+CpMEVEADABAECAJjwHKBdu3bp7rvvVm5urnw+n7Zs2RLxvHNOy5cvV05OjgYNGqTi4mIdPHgwVvMCAPoIzwFqb29XQUGBVq1a1e3zK1eu1Isvvqg1a9Zo9+7duvrqq1VSUqIzZ85c9rAAgL7D84cQSktLVVpa2u1zzjm98MILevLJJzVz5kxJ0quvvqrs7Gxt2bJFc+fOvbxpAQB9RkzfA2psbFRzc7OKi4vDjwUCARUWFqqmpvsfo9vR0aFQKBSxAQD6vpgGqLm5WZKUnZ0d8Xh2dnb4uS+rqKhQIBAIb3l5ebEcCQCQoMw/BVdeXq7W1tbw1tTUZD0SAKAXxDRAwWBQktTS0hLxeEtLS/i5L/P7/UpPT4/YAAB9X0wDlJ+fr2AwqMrKyvBjoVBIu3fvVlFRUSwPBQBIcp4/BXfq1Ck1NDSEv25sbNS+ffuUkZGh4cOHa+nSpfrZz36m6667Tvn5+XrqqaeUm5urWbNmxXJuAECS8xygPXv26I477gh/vWzZMknSvHnztG7dOj3++ONqb2/XwoULdfLkSd12223avn27Bg4cGLupAQBJz+ecS6i7AYZCIQUCAU3VTA3wpViPgyTVf3R+VOsGvnzK85rleds8rxmXmtiv7dH/c4HnNd/c6PO8JvWdPZ7XIPGdc52q0la1trZ+5fv65p+CAwBcmQgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC849jAHqb+06B5zX/ce3/iOpY915zIopViXtn61v3zo1qXe7vvP8zpb5TG9WxcOXiCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSNGrDq6b4HnN4luqPK+J7qaiveeRo9/xvKb2N3/neU3WP/0vz2skyZ37OKp1gBdcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKdT+7wujWnf2of/rec3Bb/06qmP1lt+evsbzmucfedDzGv97+z2vGdpR43mN87wC6D1cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKfTrXz4f1brrUwbGeJLY+bjzTFTr/nHZIs9rBm7/vec13CQU4AoIAGCEAAEATHgO0K5du3T33XcrNzdXPp9PW7ZsiXh+/vz58vl8EduMGTNiNS8AoI/wHKD29nYVFBRo1apVPe4zY8YMHTt2LLxt2LDhsoYEAPQ9nj+EUFpaqtLS0q/cx+/3KxgMRj0UAKDvi8t7QFVVVcrKytINN9ygxYsX68SJEz3u29HRoVAoFLEBAPq+mAdoxowZevXVV1VZWalf/OIXqq6uVmlpqc6fP9/t/hUVFQoEAuEtLy8v1iMBABJQzP8e0Ny5c8O/HjdunMaPH69Ro0apqqpK06ZNu2j/8vJyLVu2LPx1KBQiQgBwBYj7x7BHjhypzMxMNTQ0dPu83+9Xenp6xAYA6PviHqAjR47oxIkTysnJifehAABJxPMfwZ06dSriaqaxsVH79u1TRkaGMjIy9Mwzz2jOnDkKBoM6dOiQHn/8cY0ePVolJSUxHRwAkNw8B2jPnj264447wl9//v7NvHnztHr1au3fv1+vvPKKTp48qdzcXE2fPl0//elP5ff7Yzc1ACDpeQ7Q1KlT5VzPt1J85513LmsgfGFAMNvzmqY1GZ7XjE6p87wm0VUci+7uGwPf8n5jUeBy+f7uZs9r3N7/HYdJehf3ggMAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJmP9IbsTO8dKRntfsnbgqiiP5oljTe+Z9cqfnNX/93uAojxaKch0S2Zm/nxTVuqaS3vm98Q/FWz2veePGYBwm6V1cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKRLef87Z4XnNrzdMjepYR/7TTZ7XHH3aeV7z0HU1ntcget8e9N+jWjfZ3xXjSbr3L2ei+U8xNyMFACAqBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkaawNr/XZv1CAlhQmp/72uG/Ut0B/ttlOuQ0Pr7ovt/7fPe7zOr//rX0Z7XbF9wu+c1Pv2r5zWJhisgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAENyNNYJtu+bXnNaEu73dPTO830PMa4Ms63DnPaxrOdXles7N9jOc1m//LdM9rojXoaLvnNb665L+xaDS4AgIAmCBAAAATngJUUVGhiRMnKi0tTVlZWZo1a5bq6+sj9jlz5ozKyso0ZMgQXXPNNZozZ45aWlpiOjQAIPl5ClB1dbXKyspUW1urHTt2qLOzU9OnT1d7+xd/5vnoo4/qrbfe0qZNm1RdXa2jR4/qnnvuifngAIDk5ulDCNu3b4/4et26dcrKylJdXZ2mTJmi1tZW/eY3v9H69et15513SpLWrl2rG2+8UbW1tbr11ltjNzkAIKld1ntAra2tkqSMjAxJUl1dnTo7O1VcXBzeZ8yYMRo+fLhqamq6/R4dHR0KhUIRGwCg74s6QF1dXVq6dKkmT56ssWPHSpKam5uVmpqqwYMHR+ybnZ2t5ubmbr9PRUWFAoFAeMvLy4t2JABAEok6QGVlZTpw4IA2btx4WQOUl5ertbU1vDU1NV3W9wMAJIeo/iLqkiVLtG3bNu3atUvDhg0LPx4MBnX27FmdPHky4iqopaVFwWCw2+/l9/vl9/ujGQMAkMQ8XQE557RkyRJt3rxZO3fuVH5+fsTzEyZMUEpKiiorK8OP1dfX6/DhwyoqKorNxACAPsHTFVBZWZnWr1+vrVu3Ki0tLfy+TiAQ0KBBgxQIBPTwww9r2bJlysjIUHp6uh555BEVFRXxCTgAQARPAVq9erUkaerUqRGPr127VvPnz5ckPf/88+rXr5/mzJmjjo4OlZSU6Fe/+lVMhgUA9B0+55z3u1fGUSgUUiAQ0FTN1ABfivU4SefoY9/xvKZzUltUx1p40wee1/zg2oaojpXIZjfc5XnNxy1D4zCJrXOHr/a8ZtRjtXGYBNbOuU5VaataW1uVnp7e437cCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmovqJqEhcub/8sNeOtf07t3tes/G6kjhMYmto1RHPa0Z88m9xmARILlwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpoub78F89r7m29+6V2mvOWQ8AJCmugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATngJUUVGhiRMnKi0tTVlZWZo1a5bq6+sj9pk6dap8Pl/EtmjRopgODQBIfp4CVF1drbKyMtXW1mrHjh3q7OzU9OnT1d7eHrHfggULdOzYsfC2cuXKmA4NAEh+A7zsvH379oiv161bp6ysLNXV1WnKlCnhx6+66ioFg8HYTAgA6JMu6z2g1tZWSVJGRkbE46+99poyMzM1duxYlZeX6/Tp0z1+j46ODoVCoYgNAND3eboC+ltdXV1aunSpJk+erLFjx4Yff+CBBzRixAjl5uZq//79euKJJ1RfX68333yz2+9TUVGhZ555JtoxAABJyuecc9EsXLx4sX73u9/p/fff17Bhw3rcb+fOnZo2bZoaGho0atSoi57v6OhQR0dH+OtQKKS8vDxN1UwN8KVEMxoAwNA516kqbVVra6vS09N73C+qK6AlS5Zo27Zt2rVr11fGR5IKCwslqccA+f1++f3+aMYAACQxTwFyzumRRx7R5s2bVVVVpfz8/Euu2bdvnyQpJycnqgEBAH2TpwCVlZVp/fr12rp1q9LS0tTc3CxJCgQCGjRokA4dOqT169frrrvu0pAhQ7R//349+uijmjJlisaPHx+XfwAAQHLy9B6Qz+fr9vG1a9dq/vz5ampq0ve+9z0dOHBA7e3tysvL0+zZs/Xkk09+5Z8D/q1QKKRAIMB7QACQpOLyHtClWpWXl6fq6mov3xIAcIXiXnAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMDrAf4MuecJOmcOiVnPAwAwLNz6pT0xX/Pe5JwAWpra5Mkva+3jScBAFyOtrY2BQKBHp/3uUslqpd1dXXp6NGjSktLk8/ni3guFAopLy9PTU1NSk9PN5rQHufhAs7DBZyHCzgPFyTCeXDOqa2tTbm5uerXr+d3ehLuCqhfv34aNmzYV+6Tnp5+Rb/APsd5uIDzcAHn4QLOwwXW5+Grrnw+x4cQAAAmCBAAwERSBcjv92vFihXy+/3Wo5jiPFzAebiA83AB5+GCZDoPCfchBADAlSGproAAAH0HAQIAmCBAAAATBAgAYCJpArRq1Sp985vf1MCBA1VYWKjf//731iP1uqefflo+ny9iGzNmjPVYcbdr1y7dfffdys3Nlc/n05YtWyKed85p+fLlysnJ0aBBg1RcXKyDBw/aDBtHlzoP8+fPv+j1MWPGDJth46SiokITJ05UWlqasrKyNGvWLNXX10fsc+bMGZWVlWnIkCG65pprNGfOHLW0tBhNHB9f5zxMnTr1otfDokWLjCbuXlIE6PXXX9eyZcu0YsUKffTRRyooKFBJSYmOHz9uPVqvu/nmm3Xs2LHw9v7771uPFHft7e0qKCjQqlWrun1+5cqVevHFF7VmzRrt3r1bV199tUpKSnTmzJlenjS+LnUeJGnGjBkRr48NGzb04oTxV11drbKyMtXW1mrHjh3q7OzU9OnT1d7eHt7n0Ucf1VtvvaVNmzapurpaR48e1T333GM4dex9nfMgSQsWLIh4PaxcudJo4h64JDBp0iRXVlYW/vr8+fMuNzfXVVRUGE7V+1asWOEKCgqsxzAlyW3evDn8dVdXlwsGg+7ZZ58NP3by5Enn9/vdhg0bDCbsHV8+D845N2/ePDdz5kyTeawcP37cSXLV1dXOuQv/7lNSUtymTZvC+/zxj390klxNTY3VmHH35fPgnHPf/e533Q9+8AO7ob6GhL8COnv2rOrq6lRcXBx+rF+/fiouLlZNTY3hZDYOHjyo3NxcjRw5Ug8++KAOHz5sPZKpxsZGNTc3R7w+AoGACgsLr8jXR1VVlbKysnTDDTdo8eLFOnHihPVIcdXa2ipJysjIkCTV1dWps7Mz4vUwZswYDR8+vE+/Hr58Hj732muvKTMzU2PHjlV5eblOnz5tMV6PEu5mpF/26aef6vz588rOzo54PDs7W3/605+MprJRWFiodevW6YYbbtCxY8f0zDPP6Pbbb9eBAweUlpZmPZ6J5uZmSer29fH5c1eKGTNm6J577lF+fr4OHTqkH//4xyotLVVNTY369+9vPV7MdXV1aenSpZo8ebLGjh0r6cLrITU1VYMHD47Yty+/Hro7D5L0wAMPaMSIEcrNzdX+/fv1xBNPqL6+Xm+++abhtJESPkD4QmlpafjX48ePV2FhoUaMGKE33nhDDz/8sOFkSARz584N/3rcuHEaP368Ro0apaqqKk2bNs1wsvgoKyvTgQMHroj3Qb9KT+dh4cKF4V+PGzdOOTk5mjZtmg4dOqRRo0b19pjdSvg/gsvMzFT//v0v+hRLS0uLgsGg0VSJYfDgwbr++uvV0NBgPYqZz18DvD4uNnLkSGVmZvbJ18eSJUu0bds2vffeexE/viUYDOrs2bM6efJkxP599fXQ03noTmFhoSQl1Osh4QOUmpqqCRMmqLKyMvxYV1eXKisrVVRUZDiZvVOnTunQoUPKycmxHsVMfn6+gsFgxOsjFApp9+7dV/zr48iRIzpx4kSfen0457RkyRJt3rxZO3fuVH5+fsTzEyZMUEpKSsTrob6+XocPH+5Tr4dLnYfu7Nu3T5IS6/Vg/SmIr2Pjxo3O7/e7devWuT/84Q9u4cKFbvDgwa65udl6tF71wx/+0FVVVbnGxkb3wQcfuOLiYpeZmemOHz9uPVpctbW1ub1797q9e/c6Se65555ze/fudZ988olzzrmf//znbvDgwW7r1q1u//79bubMmS4/P9999tlnxpPH1ledh7a2NvfYY4+5mpoa19jY6N5991337W9/21133XXuzJkz1qPHzOLFi10gEHBVVVXu2LFj4e306dPhfRYtWuSGDx/udu7c6fbs2eOKiopcUVGR4dSxd6nz0NDQ4H7yk5+4PXv2uMbGRrd161Y3cuRIN2XKFOPJIyVFgJxz7qWXXnLDhw93qampbtKkSa62ttZ6pF533333uZycHJeamuq+8Y1vuPvuu881NDRYjxV37733npN00TZv3jzn3IWPYj/11FMuOzvb+f1+N23aNFdfX287dBx81Xk4ffq0mz59uhs6dKhLSUlxI0aMcAsWLOhz/5PW3T+/JLd27drwPp999pn7/ve/76699lp31VVXudmzZ7tjx47ZDR0HlzoPhw8fdlOmTHEZGRnO7/e70aNHux/96EeutbXVdvAv4ccxAABMJPx7QACAvokAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMPH/AIczqGSddqkzAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "()\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "index = 187\n",
        "\n",
        "plt.imshow(X_train[index])\n",
        "plt.show()\n",
        "\n",
        "print(y_train[index])\n",
        "print(y_train[index].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the actual y value for index 128 is 1 — meaning that it represents the number 1. The shape is () and hence we are really talking about a scalar value.\n",
        "\n",
        "If we wanted to create a Neural Network, the best choice for this dataset would be to apply sparce categorical crossentropy loss— for the simple reason that we don’t have to apply one-hot encoding if we use that loss function.\n",
        "\n",
        "Because we do want to illustrate how one-hot encoding works with TensorFlow and Keras, we use categorical crossentropy loss instead, so we must apply one-hot encoding to the samples.\n",
        "\n"
      ],
      "metadata": {
        "id": "13EZubNP7fEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying One-Hot Encoding to the samples\n",
        "\n",
        "If we need to convert our dataset into categorical format (and hence one-hot encoded format), we can do so using Scikit-learn’s OneHotEncodermodule. However, TensorFlow also offers its own implementation: tensorflow.keras.utils.to_categorical. It's a utility function which allows us to convert integer targets into categorical and hence one-hot encoded ones."
      ],
      "metadata": {
        "id": "icWf-s8n9yiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "print(y_train[index])\n",
        "print(y_train[index].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwLvra_s94f_",
        "outputId": "d89c5f85-6f63-4e92-8d26-8ce7766bff51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "(10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that our target vector has ten values (by means of the (10,) shape), one for each individual digit. The third is one while the others are zero, indicating that we are talking about the number 2, but then in one-hot encoded format. Exactly the same as our original integer value!"
      ],
      "metadata": {
        "id": "hX6TkHQB-rI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Convert targets into one-hot encoded format\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEaNW4yE-xDJ",
        "outputId": "84fed8d5-21ad-4a1b-9de6-b189931e528d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "change runtime to T4"
      ],
      "metadata": {
        "id": "uqD_b-nh_jyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical, normalize\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Configuration options\n",
        "no_classes = len(np.unique(y_train))\n",
        "img_width, img_height = 28, 28\n",
        "validation_split = 0.20\n",
        "no_epochs = 25\n",
        "verbosity = 1\n",
        "batch_size = 250\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape(X_train.shape[0], img_width, img_height, 1)\n",
        "X_test =  X_test.reshape(X_test.shape[0], img_width, img_height, 1)\n",
        "input_shape = (img_width, img_height, 1)\n",
        "\n",
        "# Convert targets into one-hot encoded format\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Normalize the data\n",
        "X_train = normalize(X_train)\n",
        "X_test = normalize(X_test)\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit data to model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=no_epochs,\n",
        "          verbose=verbosity,\n",
        "          validation_split=validation_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmDqL93Y_KOn",
        "outputId": "976e8e0a-e45c-4902-8729-4ab150811283"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "192/192 [==============================] - 7s 17ms/step - loss: 0.2098 - accuracy: 0.9343 - val_loss: 0.0754 - val_accuracy: 0.9774\n",
            "Epoch 2/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0549 - accuracy: 0.9827 - val_loss: 0.0698 - val_accuracy: 0.9789\n",
            "Epoch 3/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.0674 - val_accuracy: 0.9809\n",
            "Epoch 4/25\n",
            "192/192 [==============================] - 4s 19ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0646 - val_accuracy: 0.9814\n",
            "Epoch 5/25\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0771 - val_accuracy: 0.9817\n",
            "Epoch 6/25\n",
            "192/192 [==============================] - 4s 21ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0779 - val_accuracy: 0.9815\n",
            "Epoch 7/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0760 - val_accuracy: 0.9804\n",
            "Epoch 8/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0836 - val_accuracy: 0.9833\n",
            "Epoch 9/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1064 - val_accuracy: 0.9802\n",
            "Epoch 10/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0820 - val_accuracy: 0.9825\n",
            "Epoch 11/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0898 - val_accuracy: 0.9835\n",
            "Epoch 12/25\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0913 - val_accuracy: 0.9831\n",
            "Epoch 13/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0870 - val_accuracy: 0.9842\n",
            "Epoch 14/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0960 - val_accuracy: 0.9836\n",
            "Epoch 15/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0892 - val_accuracy: 0.9829\n",
            "Epoch 16/25\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0892 - val_accuracy: 0.9843\n",
            "Epoch 17/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0955 - val_accuracy: 0.9821\n",
            "Epoch 18/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.1054 - val_accuracy: 0.9802\n",
            "Epoch 19/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0866 - val_accuracy: 0.9827\n",
            "Epoch 20/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0977 - val_accuracy: 0.9812\n",
            "Epoch 21/25\n",
            "192/192 [==============================] - 3s 18ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0966 - val_accuracy: 0.9822\n",
            "Epoch 22/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 3.2706e-04 - accuracy: 0.9999 - val_loss: 0.0928 - val_accuracy: 0.9852\n",
            "Epoch 23/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 1.9772e-05 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9854\n",
            "Epoch 24/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 1.1688e-05 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9853\n",
            "Epoch 25/25\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 8.8747e-06 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9853\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d8e9b09cb80>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}