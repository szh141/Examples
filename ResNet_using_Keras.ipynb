{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOND6GRnciJHr9wHWKZV/zM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szh141/Examples/blob/main/ResNet_using_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/@francescofranco_39234/build-a-resnet-from-scratch-with-tensorflow-and-keras-1b47ba6dd0f5"
      ],
      "metadata": {
        "id": "0T7BfZwhg4bP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l_ZHEnLJg3iY"
      },
      "outputs": [],
      "source": [
        "def model_configuration():\n",
        " \"\"\"\n",
        "  Get configuration variables for the model.\n",
        " \"\"\"\n",
        "\n",
        " # Load dataset for computing dataset size\n",
        " (input_train, _), (_, _) = load_dataset()\n",
        "\n",
        " # Generic config\n",
        " width, height, channels = 32, 32, 3\n",
        " batch_size = 128\n",
        " num_classes = 10\n",
        " validation_split = 0.1 # 45/5 per the He et al. paper\n",
        " verbose = 1\n",
        " n = 3\n",
        " init_fm_dim = 16\n",
        " shortcut_type = \"identity\" # or: projection\n",
        "\n",
        " # Dataset size\n",
        " train_size = (1 - validation_split) * len(input_train)\n",
        " val_size = (validation_split) * len(input_train)\n",
        "\n",
        " # Number of steps per epoch is dependent on batch size\n",
        " maximum_number_iterations = 64000 # per the He et al. paper\n",
        " steps_per_epoch = tensorflow.math.floor(train_size / batch_size)\n",
        " val_steps_per_epoch = tensorflow.math.floor(val_size / batch_size)\n",
        " epochs = tensorflow.cast(tensorflow.math.floor(maximum_number_iterations / steps_per_epoch),\\\n",
        "  dtype=tensorflow.int64)\n",
        "\n",
        " # Define loss function\n",
        " loss = tensorflow.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        " # Learning rate config per the He et al. paper\n",
        " boundaries = [32000, 48000]\n",
        " values = [0.1, 0.01, 0.001]\n",
        " lr_schedule = schedules.PiecewiseConstantDecay(boundaries, values)\n",
        "\n",
        " # Set layer init\n",
        " initializer = tensorflow.keras.initializers.HeNormal()\n",
        "\n",
        " # Define optimizer\n",
        " optimizer_momentum = 0.9\n",
        " optimizer_additional_metrics = [\"accuracy\"]\n",
        " optimizer = SGD(learning_rate=lr_schedule, momentum=optimizer_momentum)\n",
        "\n",
        " # Load Tensorboard callback\n",
        " tensorboard = TensorBoard(\n",
        "   log_dir=os.path.join(os.getcwd(), \"logs\"),\n",
        "   histogram_freq=1,\n",
        "   write_images=True\n",
        " )\n",
        "\n",
        " # Save a model checkpoint after every epoch\n",
        " checkpoint = ModelCheckpoint(\n",
        "  os.path.join(os.getcwd(), \"model_checkpoint\"),\n",
        "  save_freq=\"epoch\"\n",
        " )\n",
        "\n",
        " # Add callbacks to list\n",
        " callbacks = [\n",
        "   tensorboard,\n",
        "   checkpoint\n",
        " ]\n",
        "\n",
        " # Create config dictionary\n",
        " config = {\n",
        "  \"width\": width,\n",
        "  \"height\": height,\n",
        "  \"dim\": channels,\n",
        "  \"batch_size\": batch_size,\n",
        "  \"num_classes\": num_classes,\n",
        "  \"validation_split\": validation_split,\n",
        "  \"verbose\": verbose,\n",
        "  \"stack_n\": n,\n",
        "  \"initial_num_feature_maps\": init_fm_dim,\n",
        "  \"training_ds_size\": train_size,\n",
        "  \"steps_per_epoch\": steps_per_epoch,\n",
        "  \"val_steps_per_epoch\": val_steps_per_epoch,\n",
        "  \"num_epochs\": epochs,\n",
        "  \"loss\": loss,\n",
        "  \"optim\": optimizer,\n",
        "  \"optim_learning_rate_schedule\": lr_schedule,\n",
        "  \"optim_momentum\": optimizer_momentum,\n",
        "  \"optim_additional_metrics\": optimizer_additional_metrics,\n",
        "  \"initializer\": initializer,\n",
        "  \"callbacks\": callbacks,\n",
        "  \"shortcut_type\": shortcut_type\n",
        " }\n",
        "\n",
        " return config"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        " \"\"\"\n",
        "  Load the CIFAR-10 dataset\n",
        " \"\"\"\n",
        " return cifar10.load_data()"
      ],
      "metadata": {
        "id": "OuO5rwAP2X3D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_crop(img, random_crop_size):\n",
        "    # Note: image_data_format is 'channel_last'\n",
        "    # SOURCE: https://jkjung-avt.github.io/keras-image-cropping/\n",
        "    assert img.shape[2] == 3\n",
        "    height, width = img.shape[0], img.shape[1]\n",
        "    dy, dx = random_crop_size\n",
        "    x = np.random.randint(0, width - dx + 1)\n",
        "    y = np.random.randint(0, height - dy + 1)\n",
        "    return img[y:(y+dy), x:(x+dx), :]\n",
        "\n",
        "\n",
        "def crop_generator(batches, crop_length):\n",
        "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
        "    crops from the image batches generated by the original iterator.\n",
        "    SOURCE: https://jkjung-avt.github.io/keras-image-cropping/\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        batch_x, batch_y = next(batches)\n",
        "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
        "        for i in range(batch_x.shape[0]):\n",
        "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
        "        yield (batch_crops, batch_y)"
      ],
      "metadata": {
        "id": "zXwEpdJu2qq_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessed_dataset():\n",
        " \"\"\"\n",
        "  Load and preprocess the CIFAR-10 dataset.\n",
        " \"\"\"\n",
        " (input_train, target_train), (input_test, target_test) = load_dataset()\n",
        "\n",
        " # Retrieve shape from model configuration and unpack into components\n",
        " config = model_configuration()\n",
        " width, height, dim = config.get(\"width\"), config.get(\"height\"),\\\n",
        "  config.get(\"dim\")\n",
        " num_classes = config.get(\"num_classes\")\n",
        "\n",
        " # Data augmentation: perform zero padding on datasets\n",
        " paddings = tensorflow.constant([[0, 0,], [4, 4], [4, 4], [0, 0]])\n",
        " input_train = tensorflow.pad(input_train, paddings, mode=\"CONSTANT\")\n",
        "\n",
        " # Convert scalar targets to categorical ones\n",
        " target_train = tensorflow.keras.utils.to_categorical(target_train, num_classes)\n",
        " target_test = tensorflow.keras.utils.to_categorical(target_test, num_classes)\n",
        "\n",
        " # Data generator for training data\n",
        " train_generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
        "  validation_split = config.get(\"validation_split\"),\n",
        "  horizontal_flip = True,\n",
        "  rescale = 1./255,\n",
        "  preprocessing_function = tensorflow.keras.applications.resnet50.preprocess_input\n",
        " )\n",
        "\n",
        " # Generate training and validation batches\n",
        " train_batches = train_generator.flow(input_train, target_train, batch_size=config.get(\"batch_size\"), subset=\"training\")\n",
        " validation_batches = train_generator.flow(input_train, target_train, batch_size=config.get(\"batch_size\"), subset=\"validation\")\n",
        " train_batches = crop_generator(train_batches, config.get(\"height\"))\n",
        " validation_batches = crop_generator(validation_batches, config.get(\"height\"))\n",
        "\n",
        " # Data generator for testing data\n",
        " test_generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
        "  preprocessing_function = tensorflow.keras.applications.resnet50.preprocess_input,\n",
        "  rescale = 1./255)\n",
        "\n",
        " # Generate test batches\n",
        " test_batches = test_generator.flow(input_test, target_test, batch_size=config.get(\"batch_size\"))\n",
        "\n",
        " return train_batches, validation_batches, test_batches"
      ],
      "metadata": {
        "id": "RQWGQBPP20Sz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, number_of_filters, match_filter_size=False):\n",
        " \"\"\"\n",
        "  Residual block with\n",
        " \"\"\"\n",
        " # Retrieve initializer\n",
        " config = model_configuration()\n",
        " initializer = config.get(\"initializer\")\n",
        "\n",
        " # Create skip connection\n",
        " x_skip = x\n",
        "\n",
        " # Perform the original mapping\n",
        " if match_filter_size:\n",
        "  x = Conv2D(number_of_filters, kernel_size=(3, 3), strides=(2,2),\\\n",
        "   kernel_initializer=initializer, padding=\"same\")(x_skip)\n",
        " else:\n",
        "  x = Conv2D(number_of_filters, kernel_size=(3, 3), strides=(1,1),\\\n",
        "   kernel_initializer=initializer, padding=\"same\")(x_skip)\n",
        " x = BatchNormalization(axis=3)(x)\n",
        " x = Activation(\"relu\")(x)\n",
        " x = Conv2D(number_of_filters, kernel_size=(3, 3),\\\n",
        "  kernel_initializer=initializer, padding=\"same\")(x)\n",
        " x = BatchNormalization(axis=3)(x)\n",
        "\n",
        " # Perform matching of filter numbers if necessary\n",
        " if match_filter_size and config.get(\"shortcut_type\") == \"identity\":\n",
        "  x_skip = Lambda(lambda x: tensorflow.pad(x[:, ::2, ::2, :], tensorflow.constant([[0, 0,], [0, 0], [0, 0], [number_of_filters//4, number_of_filters//4]]), mode=\"CONSTANT\"))(x_skip)\n",
        " elif match_filter_size and config.get(\"shortcut_type\") == \"projection\":\n",
        "  x_skip = Conv2D(number_of_filters, kernel_size=(1,1),\\\n",
        "   kernel_initializer=initializer, strides=(2,2))(x_skip)\n",
        "\n",
        " # Add the skip connection to the regular mapping\n",
        " x = Add()([x, x_skip])\n",
        "\n",
        " # Nonlinearly activate the result\n",
        " x = Activation(\"relu\")(x)\n",
        "\n",
        " # Return the result\n",
        " return x"
      ],
      "metadata": {
        "id": "h2RqxoFs27P7"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}