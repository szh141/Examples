{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLpZxE6dpZo+OTlPSNahvJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szh141/Examples/blob/main/Super_resolution_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SRGAN\n",
        "https://jonathan-hui.medium.com/gan-super-resolution-gan-srgan-b471da7270ec\n",
        "\n",
        "Super Resolution with GAN and Keras (SRGAN)\n",
        "https://dev.to/manishdhakal/super-resolution-with-gan-and-keras-srgan-38ma\n",
        "\n",
        "https://github.com/manishdhakal/SuperResolution?tab=readme-ov-file\n",
        "\n",
        "https://arxiv.org/pdf/1609.04802.pdf\n",
        "2. Method\n",
        "\n",
        "In SISR the aim is to estimate a high-resolution, superresolved image I\n",
        "SR from a low-resolution input image\n",
        "I\n",
        "LR. Here I\n",
        "LR is the low-resolution version of its highresolution counterpart I\n",
        "HR. The high-resolution images\n",
        "are only available during training. In training, I\n",
        "LR is\n",
        "obtained by applying a Gaussian filter to I\n",
        "HR followed by a\n",
        "downsampling operation with downsampling factor r. For\n",
        "an image with C color channels, we describe I\n",
        "LR by a\n",
        "real-valued tensor of size W × H × C and I\n",
        "HR, I\n",
        "SR by\n",
        "rW × rH × C respectively.\n",
        "\n",
        "Our ultimate goal is to train a generating function G that\n",
        "estimates for a given LR input image its corresponding HR\n",
        "counterpart. To achieve this, we train a generator network as\n",
        "a feed-forward CNN G\n"
      ],
      "metadata": {
        "id": "12N5Jpswgmbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras import layers, Model"
      ],
      "metadata": {
        "id": "BbwLDrU5qLUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using TensorFlow backend\n",
        "\n",
        "db_dir = \"dataset-lg\"\n",
        "def get_train_data():\n",
        "    X = []\n",
        "    Y = []\n",
        "    for x in os.listdir(db_dir + \"/train/lr\"):\n",
        "        img_x = cv2.imread(db_dir + \"/train/lr/\" + x)\n",
        "        X.append(img_x)\n",
        "\n",
        "    X = np.array(X) / 255\n",
        "\n",
        "    for y in os.listdir(db_dir + \"/train/hr\"):\n",
        "        img_y = cv2.imread(db_dir + \"/train/hr/\" + y)\n",
        "        Y.append(img_y)\n",
        "    Y = np.array(Y) / 255\n",
        "\n",
        "    return X,Y\n",
        "\n",
        "train_lr, train_hr = get_train_data()"
      ],
      "metadata": {
        "id": "u69JUIisqTtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_data():\n",
        "    X = []\n",
        "    Y = []\n",
        "    for x in os.listdir(db_dir + \"/test/lr\"):\n",
        "        img_x = cv2.imread(db_dir + \"/test/lr/\" + x)\n",
        "        X.append(img_x)\n",
        "\n",
        "    X = np.array(X) / 255\n",
        "\n",
        "    for y in os.listdir(db_dir + \"/test/hr\"):\n",
        "        img_y = cv2.imread(db_dir + \"/test/hr/\" + y)\n",
        "        Y.append(img_y)\n",
        "\n",
        "    Y = np.array(Y) / 255\n",
        "\n",
        "    return X,Y\n",
        "\n",
        "\n",
        "test_lr, test_hr = get_test_data()\n",
        "print(\"train_shape \", train_lr.shape, \" test_shape \", test_lr.shape )"
      ],
      "metadata": {
        "id": "DnLFE1MXqcT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_res_block = 16\n",
        "hr_shape = (train_hr.shape[1], train_hr.shape[2], train_hr.shape[3])\n",
        "lr_shape = (train_lr.shape[1], train_lr.shape[2], train_lr.shape[3])\n",
        "\n",
        "\n",
        "Conv2D = layers.Conv2D\n",
        "BatchNormalization = layers.BatchNormalization\n",
        "PReLU = layers.PReLU\n",
        "UpSampling2D = layers.UpSampling2D\n",
        "Dense = layers.Dense\n",
        "add = layers.add\n",
        "LeakyReLU = layers.LeakyReLU\n",
        "Input = layers.Input\n",
        "Flatten = layers.Flatten\n",
        "\n",
        "\n",
        "lr_ip = Input(shape=lr_shape)\n",
        "hr_ip = Input(shape=hr_shape)\n",
        "train_shape  (2500, 25, 25, 3)  test_shape  (500, 25, 25, 3)"
      ],
      "metadata": {
        "id": "All9as71qiMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator\n",
        "def res_block(ip):\n",
        "\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(ip)\n",
        "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
        "    res_model = PReLU(shared_axes = [1,2])(res_model)\n",
        "\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
        "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
        "\n",
        "    return add([ip,res_model])\n",
        "\n",
        "def upscale_block(ip):\n",
        "\n",
        "    up_model = Conv2D(256, (3,3), padding=\"same\")(ip)\n",
        "    up_model = UpSampling2D( size = 2 )(up_model)\n",
        "    up_model = PReLU(shared_axes=[1,2])(up_model)\n",
        "\n",
        "    return up_model"
      ],
      "metadata": {
        "id": "m5G9Tl-2qnEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Discriminator\n",
        "def discriminator_block(ip, filters, strides=1, bn=True):\n",
        "\n",
        "    disc_model = Conv2D(filters, (3,3), strides = strides, padding=\"same\")(ip)\n",
        "    disc_model = LeakyReLU( alpha=0.2 )(disc_model)\n",
        "    if bn:\n",
        "        disc_model = BatchNormalization( momentum=0.8 )(disc_model)\n",
        "\n",
        "\n",
        "    return disc_model"
      ],
      "metadata": {
        "id": "wQJ9xJcxqqc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator model\n",
        "def create_gen(gen_ip):\n",
        "    layers = Conv2D(64, (9,9), padding=\"same\")(gen_ip)\n",
        "    layers = PReLU(shared_axes=[1,2])(layers)\n",
        "\n",
        "    temp = layers\n",
        "\n",
        "    for i in range(num_res_block):\n",
        "        layers = res_block(layers)\n",
        "\n",
        "    layers = Conv2D(64, (3,3), padding=\"same\")(layers)\n",
        "    layers = BatchNormalization(momentum=0.5)(layers)\n",
        "    layers = add([layers,temp])\n",
        "\n",
        "    layers = upscale_block(layers)\n",
        "    layers = upscale_block(layers)\n",
        "\n",
        "    op = Conv2D(3, (9,9), padding=\"same\")(layers)\n",
        "\n",
        "    return Model(inputs=gen_ip, outputs=op)\n",
        "\n",
        "# Discriminator model\n",
        "def create_disc(disc_ip):\n",
        "\n",
        "    df = 64\n",
        "\n",
        "    d1 = discriminator_block(disc_ip, df, bn=False)\n",
        "    d2 = discriminator_block(d1, df, strides=2)\n",
        "    d3 = discriminator_block(d2, df*2)\n",
        "    d4 = discriminator_block(d3, df*2, strides=2)\n",
        "    d5 = discriminator_block(d4, df*4)\n",
        "    d6 = discriminator_block(d5, df*4, strides=2)\n",
        "    d7 = discriminator_block(d6, df*8)\n",
        "    d8 = discriminator_block(d7, df*8, strides=2)\n",
        "\n",
        "    d8_5 = Flatten()(d8)\n",
        "    d9 = Dense(df*16)(d8_5)\n",
        "    d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "    validity = Dense(1, activation='sigmoid')(d10)\n",
        "\n",
        "    return Model(disc_ip, validity)\n",
        "\n",
        "# VGG19\n",
        "from keras.applications import VGG19\n",
        "\n",
        "def build_vgg():\n",
        "    vgg = VGG19(weights=\"imagenet\")\n",
        "    vgg.outputs = [vgg.layers[9].output]\n",
        "\n",
        "    img = Input(shape=hr_shape)\n",
        "\n",
        "    img_features = vgg(img)\n",
        "\n",
        "    return Model(img, img_features)"
      ],
      "metadata": {
        "id": "IHcXTjluq1TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combined Model\n",
        "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n",
        "    gen_img = gen_model(lr_ip)\n",
        "\n",
        "    gen_features = vgg(gen_img)\n",
        "\n",
        "    disc_model.trainable = False\n",
        "    validity = disc_model(gen_img)\n",
        "\n",
        "    return Model(inputs=[lr_ip, hr_ip], outputs=[validity, gen_features])\n",
        "\n",
        "generator = create_gen(lr_ip)\n",
        "discriminator = create_disc(hr_ip)\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "vgg = build_vgg()\n",
        "vgg.trainable = False\n",
        "\n",
        "\n",
        "gan_model = create_comb(generator, discriminator, vgg, lr_ip, hr_ip)\n",
        "gan_model.compile(loss=[\"binary_crossentropy\",\"mse\"], loss_weights=[1e-3, 1], optimizer=\"adam\")\n",
        "# discriminator.summary()\n",
        "# generator.summary()\n",
        "gan_model.summary()"
      ],
      "metadata": {
        "id": "jBgCWsU2rHSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "train_lr_batches = []\n",
        "train_hr_batches = []\n",
        "for it in range(int(train_hr.shape[0] / batch_size)):\n",
        "    start_idx = it * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    train_hr_batches.append(train_hr[start_idx:end_idx])\n",
        "    train_lr_batches.append(train_lr[start_idx:end_idx])\n",
        "epochs = 100\n",
        "for e in range(epochs):\n",
        "\n",
        "    gen_label = np.zeros((batch_size, 1))\n",
        "    real_label = np.ones((batch_size,1))\n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "    for b in range(len(train_hr_batches)):\n",
        "        lr_imgs = train_lr_batches[b]\n",
        "        hr_imgs = train_hr_batches[b]\n",
        "\n",
        "        gen_imgs = generator.predict_on_batch(lr_imgs)\n",
        "\n",
        "        discriminator.trainable = True\n",
        "        d_loss_gen = discriminator.train_on_batch(gen_imgs, gen_label)\n",
        "        d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n",
        "        discriminator.trainable = False\n",
        "\n",
        "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real)\n",
        "\n",
        "        image_features = vgg.predict(hr_imgs)\n",
        "\n",
        "\n",
        "        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, image_features])\n",
        "\n",
        "        d_losses.append(d_loss)\n",
        "        g_losses.append(g_loss)\n",
        "\n",
        "    g_losses = np.array(g_losses)\n",
        "    d_losses = np.array(d_losses)\n",
        "\n",
        "    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
        "    d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
        "\n",
        "    print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
        "\n",
        "    if (e+1) % 20 == 0:\n",
        "        discriminator.save_weights(\"drive/My Drive/models/sr/disc/e_\"+ str(e+1) +\".h5\")\n",
        "        generator.save_weights(\"drive/My Drive/models/sr/gen/e_\"+ str(e+1) +\".h5\")\n",
        "\n",
        "\n",
        "res = generator.predict_on_batch(train_lr_batches[0])\n",
        "plt.imshow(res[0])\n",
        "plt.show()\n",
        "plt.imshow(train_lr_batches[0][0])\n",
        "plt.show()\n",
        "plt.imshow(train_hr_batches[0][0])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KHenFCVypL7r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}