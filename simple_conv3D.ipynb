{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/PWecv9QeL3sLYaJ5FDad",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szh141/Examples/blob/main/simple_conv3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/@francescofranco_39234/simple-conv3d-example-with-keras-1bb44c93dab2"
      ],
      "metadata": {
        "id": "9DeQriCZ4H6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  A simple Conv3D example with TensorFlow 2 based Keras\n",
        "'''\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "CglCMQYw3Tfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Preparatory code --\n",
        "# Model configuration\n",
        "batch_size = 100\n",
        "no_epochs = 30\n",
        "learning_rate = 0.001\n",
        "no_classes = 10\n",
        "validation_split = 0.2\n",
        "verbosity = 1"
      ],
      "metadata": {
        "id": "KF7d0Icd3WQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 1D vector into 3D values, provided by the 3D MNIST authors at\n",
        "# https://www.kaggle.com/daavoo/3d-mnist\n",
        "def array_to_color(array, cmap=\"Oranges\"):\n",
        "  s_m = plt.cm.ScalarMappable(cmap=cmap)\n",
        "  return s_m.to_rgba(array)[:,:-1]\n",
        "\n",
        "# Reshape data into format that can be handled by Conv3D layers.\n",
        "# Courtesy of Sam Berglin; Zheming Lian; Jiahui Jang - University of Wisconsin-Madison\n",
        "# Report - https://github.com/sberglin/Projects-and-Papers/blob/master/3D%20CNN/Report.pdf\n",
        "# Code - https://github.com/sberglin/Projects-and-Papers/blob/master/3D%20CNN/network_final_version.ipynb\n",
        "def rgb_data_transform(data):\n",
        "  data_t = []\n",
        "  for i in range(data.shape[0]):\n",
        "    data_t.append(array_to_color(data[i]).reshape(16, 16, 16, 3))\n",
        "  return np.asarray(data_t, dtype=np.float32)"
      ],
      "metadata": {
        "id": "01T4op_M3aH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU-GBuCp2mR5"
      },
      "outputs": [],
      "source": [
        "# -- Process code --\n",
        "# Load the HDF5 data file\n",
        "with h5py.File(\"./full_dataset_vectors.h5\", \"r\") as hf:\n",
        "\n",
        "    # Split the data into training/test features/targets\n",
        "    X_train = hf[\"X_train\"][:]\n",
        "    targets_train = hf[\"y_train\"][:]\n",
        "    X_test = hf[\"X_test\"][:]\n",
        "    targets_test = hf[\"y_test\"][:]\n",
        "\n",
        "    # Determine sample shape\n",
        "    sample_shape = (16, 16, 16, 3)\n",
        "\n",
        "    # Reshape data into 3D format\n",
        "    X_train = rgb_data_transform(X_train)\n",
        "    X_test = rgb_data_transform(X_test)\n",
        "\n",
        "    # Convert target vectors to categorical targets\n",
        "    targets_train = to_categorical(targets_train).astype(np.integer)\n",
        "    targets_test = to_categorical(targets_test).astype(np.integer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(no_"
      ],
      "metadata": {
        "id": "AtyKLeYK21Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
        "              optimizer=tensorflow.keras.optimizers.Adam(lr=learning_rate),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit data to model\n",
        "history = model.fit(X_train, targets_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=no_epochs,\n",
        "            verbose=verbosity,\n",
        "            validation_split=validation_split)"
      ],
      "metadata": {
        "id": "9-oWnaG33fqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate generalization metrics\n",
        "score = model.evaluate(X_test, targets_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# Plot history: Categorical crossentropy & Accuracy\n",
        "plt.plot(history.history['loss'], label='Categorical crossentropy (training data)')\n",
        "plt.plot(history.history['val_loss'], label='Categorical crossentropy (validation data)')\n",
        "plt.plot(history.history['accuracy'], label='Accuracy (training data)')\n",
        "plt.plot(history.history['val_accuracy'], label='Accuracy (validation data)')\n",
        "plt.title('Model performance for 3D MNIST Keras Conv3D example')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "miqJ0T3G3gOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "high test loss with low training loss, overfitting.\n",
        "add dropout to reduce overfitting"
      ],
      "metadata": {
        "id": "5BlEw7CG3mrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(no_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "G30GEfIq3zHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "still mediocre prediction accuracy, probably needs augmentation for next step"
      ],
      "metadata": {
        "id": "Jlhqfl7e34Vc"
      }
    }
  ]
}